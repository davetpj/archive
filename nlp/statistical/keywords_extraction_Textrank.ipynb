{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91562023",
   "metadata": {},
   "source": [
    "# Text Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d028b6a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-01T13:44:48.346081Z",
     "start_time": "2021-07-01T13:44:47.996134Z"
    },
    "collapsed": true,
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'과기정통부  22일 유영민 장관 등 참석해 기념행사2021년까지 1516억원 투입  5100여종 데이터 구축민간 클라우드 통한 외부연계체계도   개방성 강화  이데일리 이재운 기자  국가 차원의 빅데이터 활용 시대가 열린다  새로운 산업 창출과 기존 산업의 변화에 이르는  혁신성장 을 위한 센터가 문을 연다  10개 분야에 걸쳐  데이터 경제 의 발전을 위한 정부의 청사진을 현실로 구현하는데 앞장선다는 계획이다 22일 과학기술정보통신부는 서울 중구 대한상공회의소에서 데이터 생태계 조성과 혁신 성장의 기반 마련을 위한  빅데이터 플랫폼 및 센터  출범식 행사를 개최했다  유영민 과기정통부 장관을 비롯해 노웅래 국회 과학기술정보방송통신위원회 위원장 등 300여명이 참가했다  10개 분야 100개 센터  3년간 1516억원 투입이미지  픽사베이빅데이터는 데이터 활용을 통해 혁신성장을 이루자는 문재인 정부의 경제 성장 핵심 요소중 하나다  문재인 대통령이 직접 올 들어 데이터 활용과 이에 따른 정보보호 보안 에 대한 중요성을 강조하기도 했다 이런 맥락 속에서 빅데이터센터는 공공과 민간이 협업해 활용도 높은 양질의 데이터를 생산 구축하고  플랫폼은 이를 수집 분석 유통하는 역할을 담당한다  과기정통부는 분야별 플랫폼 10개소와 이와 연계된 기관별 센터 100개소를 구축하는데 3년간 총 1516억원을 투입할 계획이며  올해 우선 640억원 규모의 사업을 추진하고 있다 대상 분야는  금융   카드   환경 한국수자원공사   문화 한국문화정보원   교통 한국교통연구원   헬스케어 국립암센터   유통 소비 매일방송   통신      중소기업 더존비즈온   지역경제 경기도청   산림 한국임업진흥원  등으로 현재 1차 공모를 통해 72개 빅데이터 센터를 선정했고  다음달 8일까지 2차 공모를 통해 28개를 추가 선정해 총 100개를 지원  운영할 계획이다  이를 통해 데이터 생태계를 혁신하고 기업의 경쟁력을 제고하는 역할을 수행한다 주요 활용 전략 사례를 보면 빅데이터 활용을 통해  신    시장 을 창출하는 방안을 담고 있다  금융 플랫폼의 경우 소상공인 신용평가 고도화 등을 통해 금융 취약 계층 대상 중금리 대출이자를 2   절감해 연간 1조원의 신규대출을 창출할 전망이다  유통 소비와 중소기업 플랫폼은 소상공인이나 중소기업의 폐업률 감소를  문화 플랫폼은 문화 예술 관람률과 생활체육 참여율을 높이는 방안을 모색한다  의료비 절감 헬스케어 과 기업의 매출 향상을 통한 산업 육성 통신 산림  등도 눈길을 끈다 과기정통부 제공 2021년까지 5100여종 데이터 구축     알고리즘 제공도센터는 우선 분야별 데이터 부족 문제를 해소하기 위해 올해 말까지 시장 수요가 높은 1400여종 신규 데이터를 생산 구축하고  사업이 완료되는 2021년까지 총 5100여종 양질의 풍부한 데이터를 생산 구축해 시장에 공급할 계획이다 특히 공공과 민간 사이 데이터 파일형식 등이 달라 호환이 제대로 이뤄지지 못한 문제를 해소하기 위해 개방형 표준을 적용하고  품질관리기준도 마련해 운영한다 기업들이 실제 활용 가능한 최신 데이터를 확보하는데도 수개월이 소요된다는 문제점을 개선하기 위한 방안도 추진한다  센터와 플랫폼 간 연계체계에는 민간 클라우드를 기반으로 활용하고  센터에 축적된 데이터도 계속 외부와 개방 공유하며 최신 연속성을 확보한다는 계획이다 100개 센터에서 수집된 데이터를 융합 분석한 뒤 맞춤형 데이터 제작 등 양질의 데이터로 재생산하고  기업들이 필요로 하는 데이터를 원하는 형태로 즉시 활용할 수 있도록 제공할 계획이다  다양한 분석 도구는 물론 인공지능     학습 알고리즘도 제공해 이용자가 보다 사용하기 편리한 환경을 제공한다 이밖에 필요한 데이터를 쉽게 등록하고 검색할 수 있도록 기준을 마련하고  데이터 보유와 관리에 대한 체계 거버넌스 를 논의하는  데이터 얼라이언스 를 구성해 보다 안전하게 이용하는 방안도 마련했다 유영민 과기정통부 장관은  오늘 출범식은 대한민국이 데이터 강국으로 가기 위한 초석을 놓은 자리 라며  세계 주요국들보다 데이터 경제로 나아가는 발걸음이 다소 늦었지만  빅데이터 플랫폼과 센터를 지렛대로 우리나라의 낙후된 데이터 생태계를 혁신하고 기업의 경쟁력을 한 단계 제고할 수 있도록 정책적 역량을 집중하겠다 고 밝혔다 이재운 '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "\n",
    "def get_news_by_url(url):\n",
    "    headers = {\"user-agent\": \"Mozilla/5.0\"}\n",
    "    res = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "    content = soup.select_one(\n",
    "        \"#articleBodyContents\").get_text().replace(\"\\n\", \"\")\n",
    "    content = content.replace(\n",
    "        \"// flash 오류를 우회하기 위한 함수 추가function _flash_removeCallback() {}\", \"\")\n",
    "\n",
    "    start_pos = re.search(r\"\\w+@\\w+\\.\\w+(.\\w+)?\", content).start()\n",
    "    content = content[:start_pos-1]\n",
    "    return content\n",
    "\n",
    "\n",
    "doc = get_news_by_url(\n",
    "    'https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=105&oid=018&aid=0004430108')\n",
    "doc = re.sub(\"[^가-힣 \\d]\", \" \", doc)\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317a8772",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-01T13:44:50.225496Z",
     "start_time": "2021-07-01T13:44:50.222746Z"
    }
   },
   "source": [
    "## Tokenize words using Mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfe0db12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-01T13:44:50.943729Z",
     "start_time": "2021-07-01T13:44:50.630484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "과기정통부  22일\n",
      "[('과기', 'NNG'), ('정통부', 'NNG'), ('22', 'SN'), ('일', 'NNBC'), ('유영민', 'NNP'), ('장관', 'NNG'), ('등', 'NNB'), ('참석', 'NNG'), ('해', 'XSV+EC'), ('기념행사', 'NNG')]\n",
      "['과기', '정통부', '22', '일', '유영민', '장관', '등', '참석', '해', '기념행사']\n",
      "['과기', '정통부', '유영민', '장관', '참석', '기념행사', '투입', '여종', '데이터', '구축']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()\n",
    "\n",
    "# tokens = doc 에서 POS tagging 한것\n",
    "tokens = [token for token in mecab.pos(doc)]\n",
    "\n",
    "#nodes = 모든 token 중 POS tag 가 없는것\n",
    "nodes = [t[0] for t in tokens]\n",
    "\n",
    "#vocab = 불용어 처리한것\n",
    "vocab = [t[0] for t in tokens if t[1] in ['NNG', 'NNP'] and len(t[0]) > 1]\n",
    "\n",
    "print(doc[:10])\n",
    "print(tokens[:10])\n",
    "print(nodes[:10])\n",
    "print(vocab[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74452930",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-01T10:42:56.038025Z",
     "start_time": "2021-07-01T10:42:56.035649Z"
    }
   },
   "source": [
    "## Give a unique ID to vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffb3760d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-01T10:42:56.466295Z",
     "start_time": "2021-07-01T10:42:56.461870Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab = list(set(vocab))\n",
    "\n",
    "vocab2idx = {vocab[i]: i for i in range(len(vocab))}\n",
    "idx2vocab = {i: vocab[i] for i in range(len(vocab))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34c08cd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b01c086f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-01T10:42:57.690615Z",
     "start_time": "2021-07-01T10:42:56.911128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 핵심키워드 ===\n",
      "데이터 : 7.405189e-07\n",
      "센터 : 2.49831e-07\n",
      "한국 : 2.0378042e-07\n",
      "활용 : 1.9834519e-07\n",
      "대한 : 1.9389464e-07\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "vocab_len = len(vocab2idx)\n",
    "\n",
    "# 토큰별로 그래프 edge를 Matrix 형태로 생성\n",
    "weighted_edge = np.zeros((vocab_len, vocab_len), dtype=np.float32)\n",
    "\n",
    "# 각 토큰 노드별로 스코어 1로 초기화\n",
    "score = np.ones((vocab_len), dtype=np.float32)\n",
    "\n",
    "# coocurrence를 판단하기 위한 window 사이즈 설정\n",
    "window_size = 3\n",
    "covered_coocurrences = []\n",
    "\n",
    "for window_start in range(len(nodes) - window_size + 1):\n",
    "    window = nodes[window_start:window_start+window_size]\n",
    "\n",
    "    for i in range(window_size):\n",
    "        for j in range(i+1, window_size):\n",
    "            if window[i] in vocab and window[j] in vocab:\n",
    "                index_i = window_start + i\n",
    "                index_j = window_start + j\n",
    "\n",
    "                if (index_i, index_j) not in covered_coocurrences:\n",
    "                    weighted_edge[vocab2idx[window[i]]\n",
    "                                  ][vocab2idx[window[j]]] = 1\n",
    "                    weighted_edge[vocab2idx[window[j]]\n",
    "                                  ][vocab2idx[window[i]]] = 1\n",
    "                    covered_coocurrences.append((index_i, index_j))\n",
    "\n",
    "for i in range(vocab_len):\n",
    "    row_sum = weighted_edge[i].sum()\n",
    "    weighted_edge[i] = weighted_edge[i]/row_sum if row_sum > 0 else 0\n",
    "\n",
    "MAX_ITERATIONS = 50\n",
    "d = 0.85\n",
    "threshold = 0.0001  # convergence threshold\n",
    "\n",
    "for iter in range(MAX_ITERATIONS):\n",
    "    prev_score = np.copy(score)\n",
    "\n",
    "    for i in range(vocab_len):\n",
    "        summation = 0\n",
    "        for j in range(vocab_len):\n",
    "            if weighted_edge[j][i] != 0:\n",
    "                summation += weighted_edge[j][i] * prev_score[j]\n",
    "\n",
    "        score[i] = (1 - d) * d*summation\n",
    "\n",
    "    if np.sum(np.fabs(prev_score - score)) <= threshold:\n",
    "        break\n",
    "\n",
    "\n",
    "sorted_index = np.flip(np.argsort(score), 0)\n",
    "\n",
    "n = 5\n",
    "\n",
    "\n",
    "print(\"\\n=== 핵심키워드 ===\")\n",
    "for i in range(0, n):\n",
    "    print(str(idx2vocab[sorted_index[i]])+\" : \" + str(score[sorted_index[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c9779e",
   "metadata": {},
   "source": [
    "# Mini note"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d17786",
   "metadata": {},
   "source": [
    "![ex_screenshot](../img/textrank1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e64c711",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-01T14:06:14.558076Z",
     "start_time": "2021-07-01T14:06:14.550719Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'바나나': 0, '사과': 1, '파인애플': 2, '딸기': 3}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = ['딸기', '바나나', '사과', '딸기', '파인애플']\n",
    "nodes = ['바나나', '사과', '파인애플', '딸기']\n",
    "vocab = nodes\n",
    "\n",
    "# [vocab2idx[token] for token in vocab] \n",
    "\n",
    "vocab2idx = {vocab[i]:i for i in range(0, len(vocab))} #vocab을 인덱스로 변환\n",
    "idx2vocab = {i:vocab[i] for i in range(0, len(vocab))} #인덱스를 vocab으로 변환\n",
    "vocab2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2b47b8",
   "metadata": {},
   "source": [
    "![ex_screenshot](../img/textrank2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aab6e9e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-01T14:29:27.151722Z",
     "start_time": "2021-07-01T14:29:27.137546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_start 0\n",
      "['딸기', '바나나']\n",
      "i 0\n",
      "j 1\n",
      "3\n",
      "0\n",
      "i 1\n",
      "window_start 1\n",
      "['바나나', '사과']\n",
      "i 0\n",
      "j 1\n",
      "0\n",
      "1\n",
      "i 1\n",
      "window_start 2\n",
      "['사과', '딸기']\n",
      "i 0\n",
      "j 1\n",
      "1\n",
      "3\n",
      "i 1\n",
      "window_start 3\n",
      "['딸기', '파인애플']\n",
      "i 0\n",
      "j 1\n",
      "3\n",
      "2\n",
      "i 1\n",
      "0 : 2.0\n",
      "1 : 2.0\n",
      "2 : 1.0\n",
      "3 : 3.0\n",
      "[[0.         0.5        0.         0.5       ]\n",
      " [0.5        0.         0.         0.5       ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.33333334 0.33333334 0.33333334 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "vocab_len = len(vocab)\n",
    "\n",
    "# 토큰별로 그래프 edge를 Matrix 형태로 생성\n",
    "weighted_edge = np.zeros((vocab_len,vocab_len),dtype=np.float32)\n",
    "\n",
    "# 각 토큰 노드별로 스코어 1로 초기화\n",
    "score = np.ones((vocab_len),dtype=np.float32)\n",
    "\n",
    "# coocurrence를 판단하기 위한 window 사이즈 설정\n",
    "window_size = 2\n",
    "covered_cooccurence = []\n",
    "\n",
    "tokens = ['딸기', '바나나', '사과', '딸기', '파인애플']\n",
    "\n",
    "for window_start in range(0, (len(tokens) - window_size + 1)):\n",
    "    window = tokens[window_start : window_start + window_size]\n",
    "    print(\"window_start\",window_start)\n",
    "    print(window)\n",
    "    \n",
    "    for i in range(window_size):\n",
    "        print(\"i\",i)\n",
    "        for j in range(i + 1, window_size):\n",
    "            print(\"j\",j)\n",
    "            if(window[i] in vocab and window[j] in vocab):\n",
    "                index_i = i + window_start\n",
    "                index_j = j + window_start\n",
    "                print(vocab2idx[window[i]])\n",
    "                print(vocab2idx[window[j]])\n",
    "\n",
    "\n",
    "                if (index_i, index_j) not in covered_cooccurence:\n",
    "                    weighted_edge[vocab2idx[window[i]]][vocab2idx[window[j]]] = 1\n",
    "                    weighted_edge[vocab2idx[window[j]]][vocab2idx[window[i]]] = 1\n",
    "                    covered_cooccurence.append((index_i, index_j))\n",
    "\n",
    "\n",
    "for i in range(vocab_len):\n",
    "    row_sum = weighted_edge[i].sum()\n",
    "    print(f\"{i} : {row_sum}\")\n",
    "    weighted_edge[i] = weighted_edge[i]/row_sum if row_sum > 0 else 0\n",
    "\n",
    "print(weighted_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5729e0cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-01T14:51:19.799087Z",
     "start_time": "2021-07-01T14:51:19.772933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** score *****\n",
      "[0.85833335 1.         1.         1.        ]\n",
      "***** score *****\n",
      "[0.85833335 0.85833335 1.         1.        ]\n",
      "***** score *****\n",
      "[0.85833335 0.85833335 0.43333334 1.        ]\n",
      "***** score *****\n",
      "[0.85833335 0.85833335 0.43333334 1.85      ]\n",
      "***** score *****\n",
      "[1.0389583  0.85833335 0.43333334 1.85      ]\n",
      "***** score *****\n",
      "[1.0389583  1.0389583  0.43333334 1.85      ]\n",
      "***** score *****\n",
      "[1.0389583 1.0389583 0.6741667 1.85     ]\n",
      "***** score *****\n",
      "[1.0389583 1.0389583 0.6741667 1.2479167]\n",
      "***** score *****\n",
      "[0.9451337 1.0389583 0.6741667 1.2479167]\n",
      "***** score *****\n",
      "[0.9451337 0.9451337 0.6741667 1.2479167]\n",
      "***** score *****\n",
      "[0.9451337 0.9451337 0.5035764 1.2479167]\n",
      "***** score *****\n",
      "[0.9451337 0.9451337 0.5035764 1.6061562]\n",
      "***** score *****\n",
      "[1.0067594 0.9451337 0.5035764 1.6061562]\n",
      "***** score *****\n",
      "[1.0067594 1.0067594 0.5035764 1.6061562]\n",
      "***** score *****\n",
      "[1.0067594 1.0067594 0.6050776 1.6061562]\n",
      "***** score *****\n",
      "[1.0067594 1.0067594 0.6050776 1.3814036]\n",
      "***** score *****\n",
      "[0.96927047 1.0067594  0.6050776  1.3814036 ]\n",
      "***** score *****\n",
      "[0.96927047 0.96927047 0.6050776  1.3814036 ]\n",
      "***** score *****\n",
      "[0.96927047 0.96927047 0.5413977  1.3814036 ]\n",
      "***** score *****\n",
      "[0.96927047 0.96927047 0.5413977  1.5200615 ]\n",
      "***** score *****\n",
      "[0.99262404 0.96927047 0.5413977  1.5200615 ]\n",
      "***** score *****\n",
      "[0.99262404 0.99262404 0.5413977  1.5200615 ]\n",
      "***** score *****\n",
      "[0.99262404 0.99262404 0.58068407 1.5200615 ]\n",
      "***** score *****\n",
      "[0.99262404 0.99262404 0.58068407 1.434068  ]\n",
      "***** score *****\n",
      "[0.97818446 0.99262404 0.58068407 1.434068  ]\n",
      "***** score *****\n",
      "[0.97818446 0.97818446 0.58068407 1.434068  ]\n",
      "***** score *****\n",
      "[0.97818446 0.97818446 0.55631924 1.434068  ]\n",
      "***** score *****\n",
      "[0.97818446 0.97818446 0.55631924 1.4873118 ]\n",
      "***** score *****\n",
      "[0.98713344 0.97818446 0.55631924 1.4873118 ]\n",
      "***** score *****\n",
      "[0.98713344 0.98713344 0.55631924 1.4873118 ]\n",
      "***** score *****\n",
      "[0.98713344 0.98713344 0.57140505 1.4873118 ]\n",
      "***** score *****\n",
      "[0.98713344 0.98713344 0.57140505 1.4543282 ]\n",
      "***** score *****\n",
      "[0.9815914  0.98713344 0.57140505 1.4543282 ]\n",
      "***** score *****\n",
      "[0.9815914  0.9815914  0.57140505 1.4543282 ]\n",
      "***** score *****\n",
      "[0.9815914  0.9815914  0.56205964 1.4543282 ]\n",
      "***** score *****\n",
      "[0.9815914  0.9815914  0.56205964 1.4747577 ]\n",
      "***** score *****\n",
      "[0.9850244  0.9815914  0.56205964 1.4747577 ]\n",
      "***** score *****\n",
      "[0.9850244  0.9850244  0.56205964 1.4747577 ]\n",
      "***** score *****\n",
      "[0.9850244 0.9850244 0.567848  1.4747577]\n",
      "***** score *****\n",
      "[0.9850244 0.9850244 0.567848  1.4621034]\n",
      "***** score *****\n",
      "[0.982898  0.9850244 0.567848  1.4621034]\n",
      "***** score *****\n",
      "[0.982898  0.982898  0.567848  1.4621034]\n",
      "***** score *****\n",
      "[0.982898  0.982898  0.5642626 1.4621034]\n",
      "***** score *****\n",
      "[0.982898  0.982898  0.5642626 1.4699416]\n",
      "***** score *****\n",
      "[0.98421514 0.982898   0.5642626  1.4699416 ]\n",
      "***** score *****\n",
      "[0.98421514 0.98421514 0.5642626  1.4699416 ]\n",
      "***** score *****\n",
      "[0.98421514 0.98421514 0.56648344 1.4699416 ]\n",
      "***** score *****\n",
      "[0.98421514 0.98421514 0.56648344 1.4650866 ]\n",
      "***** score *****\n",
      "[0.9833993  0.98421514 0.56648344 1.4650866 ]\n",
      "***** score *****\n",
      "[0.9833993  0.9833993  0.56648344 1.4650866 ]\n",
      "***** score *****\n",
      "[0.9833993 0.9833993 0.5651079 1.4650866]\n",
      "***** score *****\n",
      "[0.9833993 0.9833993 0.5651079 1.4680938]\n",
      "***** score *****\n",
      "[0.9839046 0.9833993 0.5651079 1.4680938]\n",
      "***** score *****\n",
      "[0.9839046 0.9839046 0.5651079 1.4680938]\n",
      "***** score *****\n",
      "[0.9839046  0.9839046  0.56595993 1.4680938 ]\n",
      "***** score *****\n",
      "[0.9839046  0.9839046  0.56595993 1.4662311 ]\n",
      "***** score *****\n",
      "[0.9835916  0.9839046  0.56595993 1.4662311 ]\n",
      "***** score *****\n",
      "[0.9835916  0.9835916  0.56595993 1.4662311 ]\n",
      "***** score *****\n",
      "[0.9835916 0.9835916 0.5654322 1.4662311]\n",
      "***** score *****\n",
      "[0.9835916 0.9835916 0.5654322 1.4673848]\n",
      "***** score *****\n",
      "[0.9837855 0.9835916 0.5654322 1.4673848]\n",
      "***** score *****\n",
      "[0.9837855 0.9837855 0.5654322 1.4673848]\n",
      "***** score *****\n",
      "[0.9837855  0.9837855  0.56575906 1.4673848 ]\n",
      "***** score *****\n",
      "[0.9837855  0.9837855  0.56575906 1.4666703 ]\n",
      "***** score *****\n",
      "[0.98366547 0.9837855  0.56575906 1.4666703 ]\n",
      "***** score *****\n",
      "[0.98366547 0.98366547 0.56575906 1.4666703 ]\n",
      "***** score *****\n",
      "[0.98366547 0.98366547 0.5655566  1.4666703 ]\n",
      "***** score *****\n",
      "[0.98366547 0.98366547 0.5655566  1.4671129 ]\n",
      "***** score *****\n",
      "[0.9837398  0.98366547 0.5655566  1.4671129 ]\n",
      "***** score *****\n",
      "[0.9837398 0.9837398 0.5655566 1.4671129]\n",
      "***** score *****\n",
      "[0.9837398 0.9837398 0.565682  1.4671129]\n",
      "***** score *****\n",
      "[0.9837398 0.9837398 0.565682  1.4668387]\n",
      "***** score *****\n",
      "[0.9836937 0.9837398 0.565682  1.4668387]\n",
      "***** score *****\n",
      "[0.9836937 0.9836937 0.565682  1.4668387]\n",
      "***** score *****\n",
      "[0.9836937 0.9836937 0.5656043 1.4668387]\n",
      "***** score *****\n",
      "[0.9836937 0.9836937 0.5656043 1.4670085]\n",
      "***** score *****\n",
      "[0.9837222 0.9836937 0.5656043 1.4670085]\n",
      "***** score *****\n",
      "[0.9837222 0.9837222 0.5656043 1.4670085]\n",
      "***** score *****\n",
      "[0.9837222 0.9837222 0.5656524 1.4670085]\n",
      "***** score *****\n",
      "[0.9837222 0.9837222 0.5656524 1.4669033]\n",
      "***** score *****\n",
      "[0.98370457 0.9837222  0.5656524  1.4669033 ]\n",
      "***** score *****\n",
      "[0.98370457 0.98370457 0.5656524  1.4669033 ]\n",
      "***** score *****\n",
      "[0.98370457 0.98370457 0.5656226  1.4669033 ]\n",
      "***** score *****\n",
      "[0.98370457 0.98370457 0.5656226  1.4669684 ]\n",
      "***** score *****\n",
      "[0.9837155  0.98370457 0.5656226  1.4669684 ]\n",
      "***** score *****\n",
      "[0.9837155 0.9837155 0.5656226 1.4669684]\n",
      "***** score *****\n",
      "[0.9837155  0.9837155  0.56564105 1.4669684 ]\n",
      "***** score *****\n",
      "[0.9837155  0.9837155  0.56564105 1.4669281 ]\n",
      "***** final *****\n",
      "[0.9837155  0.9837155  0.56564105 1.4669281 ]\n"
     ]
    }
   ],
   "source": [
    "MAX_ITERATIONS = 50\n",
    "d=0.85\n",
    "threshold = 0.0001 #convergence threshold\n",
    "\n",
    "for iter in range(MAX_ITERATIONS):\n",
    "    \n",
    "    # threshold 때문에 만듬\n",
    "    prev_score = np.copy(score)\n",
    "\n",
    "    for i in range(vocab_len):\n",
    "        summation = 0\n",
    "        for j in range(vocab_len):\n",
    "            summation += weighted_edge[j][i] * prev_score[j]\n",
    "\n",
    "        score[i] = (1-d) + d*summation\n",
    "        print(\"***** score *****\")\n",
    "        print(score)\n",
    "    \n",
    "    # np.fabs flaot 절대값(abs)\n",
    "    if np.sum(np.fabs(prev_score - score)) <= threshold:\n",
    "        break\n",
    "\n",
    "print(\"***** final *****\")\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1814ac27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-01T14:52:05.498544Z",
     "start_time": "2021-07-01T14:52:05.492191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 핵심키워드 ===\n",
      "딸기 : 1.4669281\n",
      "사과 : 0.9837155\n",
      "바나나 : 0.9837155\n",
      "파인애플 : 0.56564105\n"
     ]
    }
   ],
   "source": [
    "# np.argsort() <-- sort array and return index\n",
    "sorted_index = np.flip(np.argsort(score),0) \n",
    "\n",
    "n = 4\n",
    "\n",
    "print(\"\\n=== 핵심키워드 ===\")\n",
    "for i in range(0,n):\n",
    "    print(str(idx2vocab[sorted_index[i]])+\" : \" + str(score[sorted_index[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f215ebf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

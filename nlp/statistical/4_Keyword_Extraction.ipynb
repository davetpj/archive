{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1Q9mWDrgMUn"
   },
   "source": [
    "# Keyword Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpTxmnbx8v6m"
   },
   "source": [
    "## Install Mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T15:28:09.468451Z",
     "start_time": "2021-07-10T15:28:09.465275Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qsWnZkd78qCA",
    "outputId": "c551176f-1543-47d2-9584-b5b866fcf91d"
   },
   "outputs": [],
   "source": [
    "#!sudo apt-get install g++ openjdk-7-jdk # Install Java 1.7+\n",
    "#!sudo apt-get install python-dev; pip install konlpy     # Python 2.x\n",
    "#!sudo apt-get install python3-dev; pip3 install konlpy   # Python 3.x\n",
    "#!sudo apt-get install curl\n",
    "#!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxsBfWirA9ao"
   },
   "source": [
    "# TF-IDF 활용 핵심키워드 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8UYUNHDNMVp"
   },
   "source": [
    "## sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T15:28:11.310903Z",
     "start_time": "2021-07-10T15:28:09.472832Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdsHZk1UBtRP",
    "outputId": "79e2724e-63b9-49ea-ff43-d101b235381e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "\n",
    "def get_news_by_url(url):\n",
    "    headers = {\"user-agent\": \"Mozilla/5.0\"}\n",
    "    res = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "    content = soup.select_one(\n",
    "        \"#articleBodyContents\").get_text().replace(\"\\n\", \"\")\n",
    "    content = content.replace(\n",
    "        \"// flash 오류를 우회하기 위한 함수 추가function _flash_removeCallback() {}\", \"\")\n",
    "\n",
    "    start_pos = re.search(r\"\\w+@\\w+\\.\\w+(.\\w+)?\", content).start()\n",
    "    content = content[:start_pos-1]\n",
    "    return content\n",
    "\n",
    "\n",
    "docs = []\n",
    "docs.append(get_news_by_url(\n",
    "    'https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=105&oid=018&aid=0004430108'))\n",
    "docs.append(get_news_by_url(\n",
    "    'https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=101&oid=001&aid=0011614790'))\n",
    "docs.append(get_news_by_url(\n",
    "    'https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=102&oid=014&aid=0004424362'))\n",
    "docs.append(get_news_by_url(\n",
    "    'https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=101&oid=119&aid=0002402191'))\n",
    "docs.append(get_news_by_url(\n",
    "    'https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=101&oid=030&aid=0002882728'))\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Of0dQ_ALpLw6"
   },
   "source": [
    "### 1) 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T15:28:11.470763Z",
     "start_time": "2021-07-10T15:28:11.313709Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'과기 정통부 유영민 장관 참석 기념행사 투입 여종 데이터 구축 민간 클라우드 외부 연계 체계 개방 강화 데일리 이재운 기자 국가 차원 빅 데이터 활용 시대 산업 창출 기존 산업 변'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전처리\n",
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()\n",
    "\n",
    "preprocessed_docs = []\n",
    "\n",
    "\n",
    "for doc in docs:\n",
    "    token_list = []\n",
    "    for token in mecab.pos(doc):\n",
    "        if token[1] in ['NNG', 'NNP', 'VV']:\n",
    "            token_list.append(token[0])\n",
    "    preprocessed_docs.append(\" \".join(token_list))\n",
    "\n",
    "\n",
    "preprocessed_docs[0][:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JqZ9ONgLpOzv"
   },
   "source": [
    "### 2) TF-IDF 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T15:28:12.408475Z",
     "start_time": "2021-07-10T15:28:11.473603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['가공', '가능', '가입자', '가족', '가중치', '가치', '각종', '감소', '감염', '강국']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(max_df=0.85, max_features=10000)\n",
    "word_count = count_vect.fit_transform(preprocessed_docs)\n",
    "print((count_vect.get_feature_names()[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T15:28:45.158694Z",
     "start_time": "2021-07-10T15:28:45.150696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.feature_extraction.text.CountVectorizer'>\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(count_vect.fit(preprocessed_docs)))\n",
    "print(type(count_vect.fit_transform(preprocessed_docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T15:28:45.643301Z",
     "start_time": "2021-07-10T15:28:45.638114Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Okub07GQ-KJe",
    "outputId": "b911b82e-7b4a-46b0-987a-30ddac24297d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
    "tfidf_transformer.fit(word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "an6Cngd2Cwjg"
   },
   "source": [
    "### 3) 핵심키워드 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T15:28:51.702117Z",
     "start_time": "2021-07-10T15:28:51.698675Z"
    },
    "id": "yKrcZ9rh-5Rt"
   },
   "outputs": [],
   "source": [
    "def sort_keywords(keywords):\n",
    "    return sorted(zip(keywords.col, keywords.data), key=lambda x: (x[1], x[0]), reverse=True)\n",
    " \n",
    "def extract_keywords(feature_names, sorted_keywords, n=5):\n",
    "    return [(feature_names[idx], score) for idx, score in sorted_keywords[:n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T15:29:09.263387Z",
     "start_time": "2021-07-10T15:29:09.255709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 원문 =====\n",
      "과기정통부, 22일 유영민 장관 등 참석해 기념행사2021년까지 1516억원 투입, 5100여종 데이터 구축민간 클라우드 통한 외부연계체계도..\"개방성 강화\"[이데일리 이재운 기자\n",
      "\n",
      "=== 핵심키워드 ===\n",
      "('플랫', 0.25172034622187184)\n",
      "('센터', 0.22285191065929333)\n",
      "('계획', 0.21576029676160446)\n",
      "('활용', 0.18233338144851272)\n",
      "('정통부', 0.17980024730133706)\n"
     ]
    }
   ],
   "source": [
    "doc = preprocessed_docs[0]  # 핵심키워드 추출할 문서 조회\n",
    "\n",
    "feature_names = count_vect.get_feature_names()\n",
    "tfidf_vect = tfidf_transformer.transform(count_vect.transform([doc]))\n",
    "sorted_keywords = sort_keywords(tfidf_vect.tocoo())\n",
    "\n",
    "\n",
    "# 사용자가 지정한 갯수만큼 키워드 추출\n",
    "keywords = extract_keywords(feature_names, sorted_keywords, 5)\n",
    "\n",
    "print(\"\\n===== 원문 =====\")\n",
    "print(docs[0][:100])\n",
    "print(\"\\n=== 핵심키워드 ===\")\n",
    "for k in keywords:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T15:30:04.787603Z",
     "start_time": "2021-07-10T15:30:04.785011Z"
    }
   },
   "outputs": [],
   "source": [
    "#tfidf_vect.tocoo().toarray()\n",
    "#tfidf_vect.tocoo().col\n",
    "#tfidf_vect.tocoo().data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lwQjPYuxNy4K"
   },
   "source": [
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTNnFrNhOrA3"
   },
   "source": [
    "## gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aE-YzDI6OrA5"
   },
   "source": [
    "### 1) 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T15:30:21.682969Z",
     "start_time": "2021-07-10T15:30:21.650940Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "edVMwQBuOrA6",
    "outputId": "e329813f-df02-4c4e-e841-df71b464979f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'과기 정통부 일 유영민 장관 등 참석 기념행사 년 억 원 투입 여종 데이터 구축 민간 클라우드 통한 외부 연계 체계 개방 강화 데일리 이재운 기자 국가 차원 빅 데이터 활용 시대 '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()\n",
    "\n",
    "preprocessed_docs = []\n",
    "for doc in docs:\n",
    "    # 명사와 동사만으로 문서 전처리\n",
    "    preprocessed_docs.append(\n",
    "        ' '.join([token[0] for token in mecab.pos(doc) if token[1][0] in ['N', 'V']]))\n",
    "preprocessed_docs[0][:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWGsCRJUOrA8"
   },
   "source": [
    "### 2) TF-IDF 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T15:30:24.089770Z",
     "start_time": "2021-07-10T15:30:23.945236Z"
    },
    "id": "NCUzeqp3OrA9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhkim/miniforge3/envs/nlp/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "document_ls = [doc.split() for doc in preprocessed_docs]\n",
    "dct = Dictionary(document_ls)  # 인덱스(key) - 단어(valuue) 인 딕셔너리 생성\n",
    "# 각 문서에 포함된 단어를 인덱스로 변환하여 corpus 생성\n",
    "corpus = [dct.doc2bow(doc) for doc in document_ls]\n",
    "tfidf = TfidfModel(corpus)  # TF-IDF 산출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBT2h57bOrBF"
   },
   "source": [
    "### 3) 핵심키워드 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T15:30:25.952114Z",
     "start_time": "2021-07-10T15:30:25.947888Z"
    },
    "id": "Xk0Tbo21RddA"
   },
   "outputs": [],
   "source": [
    "def sort_keywords(tfidf):\n",
    "    return sorted(tfidf, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "\n",
    "\n",
    "def extract_keywords(feature_names, sorted_keywords, n=5):\n",
    "    return [(feature_names[idx], score) for idx, score in sorted_keywords[:n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T15:30:26.426047Z",
     "start_time": "2021-07-10T15:30:26.420582Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_8T0QSKVRfUt",
    "outputId": "ff60f197-d8a0-451f-91a4-70923c275575"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 핵심키워드 ===\n",
      "('플랫', 0.2495222182663338)\n",
      "('폼', 0.2495222182663338)\n",
      "('계획', 0.21387618708542896)\n",
      "('정통부', 0.17823015590452412)\n",
      "('위한', 0.17823015590452412)\n"
     ]
    }
   ],
   "source": [
    "doc = corpus[0]\n",
    "\n",
    "sorted_keywords = sort_keywords(tfidf[doc])  # TF-IDF를 기준으로 역순 정렬\n",
    "\n",
    "# 사용자가 지정한 갯수만큼 키워드 추출\n",
    "keywords = extract_keywords(dct, sorted_keywords, 5)\n",
    "\n",
    "print(\"\\n=== 핵심키워드 ===\")\n",
    "for k in keywords:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T15:30:35.603151Z",
     "start_time": "2021-07-10T15:30:35.600049Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8gBGnkhCZSlw",
    "outputId": "66814b20-b290-4061-975c-951dcc0b9153"
   },
   "outputs": [],
   "source": [
    "#tfidf[doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZpm1wtTqxL-"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfekkYshBAVS"
   },
   "source": [
    "# Textrank\n",
    "https://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bn58myMFF-nN"
   },
   "source": [
    "<img src=\"https://3.bp.blogspot.com/-yp0Lr3ec5EY/XIs6znCcO_I/AAAAAAAAAPY/xtZxe_OYtH0xeuWsp4Qd4DQrunGMpVQmQCLcBGAs/s640/keyword-extraction-textrank.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxZBz6vLlyga"
   },
   "source": [
    "## 행렬 활용 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T15:31:03.628599Z",
     "start_time": "2021-07-10T15:31:03.620028Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X-WdT3gz3FMc",
    "outputId": "7b7d8d34-5990-42b3-9600-1725f7356bb6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'바나나': 0, '사과': 1, '파인애플': 2, '딸기': 3}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = ['딸기', '바나나', '사과', '딸기', '파인애플']\n",
    "nodes = ['바나나', '사과', '파인애플', '딸기']\n",
    "vocab = nodes\n",
    "\n",
    "# [vocab2idx[token] for token in vocab] \n",
    "\n",
    "vocab2idx = {vocab[i]:i for i in range(0, len(vocab))} #vocab을 인덱스로 변환\n",
    "idx2vocab = {i:vocab[i] for i in range(0, len(vocab))} #인덱스를 vocab으로 변환\n",
    "vocab2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9Tvibn1lyg3"
   },
   "source": [
    "### 3) 그래프 생성 (weighted edge 계산)\n",
    "\n",
    "*   TextRank는 그래프 기반 모델\n",
    "*   각 단어(토큰)은 그래프의 노드(vertex) \n",
    "*   weighted_edge 행렬은 노드간 가중치 정보를 담고 있음\n",
    "*   weighted_edge[i][j] 는 i번째 단어와 j번째 단어의 가중치를 의미\n",
    "*   weighted_edge[i][j] 가 0인 경우는 노드간 연결이 없음을 의미\n",
    "*   모든 노드는 1로 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T15:31:12.391945Z",
     "start_time": "2021-07-10T15:31:12.378877Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nP8PJUnMlyg3",
    "outputId": "66629252-0223-4dcf-9eef-b27a1c26da9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 2.0\n",
      "1 : 2.0\n",
      "2 : 1.0\n",
      "3 : 3.0\n",
      "[[0.         0.5        0.         0.5       ]\n",
      " [0.5        0.         0.         0.5       ]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.33333334 0.33333334 0.33333334 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "vocab_len = len(vocab)\n",
    "\n",
    "# 토큰별로 그래프 edge를 Matrix 형태로 생성\n",
    "weighted_edge = np.zeros((vocab_len,vocab_len),dtype=np.float32)\n",
    "\n",
    "# 각 토큰 노드별로 스코어 1로 초기화\n",
    "score = np.ones((vocab_len),dtype=np.float32)\n",
    "\n",
    "# coocurrence를 판단하기 위한 window 사이즈 설정\n",
    "window_size = 2\n",
    "covered_cooccurence = []\n",
    "\n",
    "tokens = ['딸기', '바나나', '사과', '딸기', '파인애플']\n",
    "\n",
    "for window_start in range(0, (len(tokens) - window_size + 1)):\n",
    "    window = tokens[window_start : window_start + window_size]\n",
    "    \n",
    "    for i in range(window_size):\n",
    "        for j in range(i + 1, window_size):\n",
    "            if(window[i] in vocab and window[j] in vocab):\n",
    "                index_i = i + window_start\n",
    "                index_j = j + window_start\n",
    "                \n",
    "                if (index_i, index_j) not in covered_cooccurence:\n",
    "                    weighted_edge[vocab2idx[window[i]]][vocab2idx[window[j]]] = 1\n",
    "                    weighted_edge[vocab2idx[window[j]]][vocab2idx[window[i]]] = 1\n",
    "                    covered_cooccurence.append((index_i, index_j))\n",
    "\n",
    "\n",
    "for i in range(vocab_len):\n",
    "    row_sum = weighted_edge[i].sum()\n",
    "    print(f\"{i} : {row_sum}\")\n",
    "    weighted_edge[i] = weighted_edge[i]/row_sum if row_sum > 0 else 0\n",
    "\n",
    "print(weighted_edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "loXJ9c7jlyg8"
   },
   "source": [
    "### 4) 각 노드의 score계산\n",
    "각 노드와 연결된 weighted edge의 값을 합산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T15:31:39.927485Z",
     "start_time": "2021-07-10T15:31:39.921590Z"
    },
    "id": "R9IOS9Oolyg8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** score *****\n",
      "[0.98370874 0.9837155  0.56564105 1.4669281 ]\n",
      "***** score *****\n",
      "[0.98370874 0.9837059  0.56564105 1.4669281 ]\n",
      "***** score *****\n",
      "[0.98370874 0.9837059  0.56562966 1.4669281 ]\n",
      "***** score *****\n",
      "[0.98370874 0.9837059  0.56562966 1.4669365 ]\n",
      "***** final *****\n",
      "[0.98370874 0.9837059  0.56562966 1.4669365 ]\n"
     ]
    }
   ],
   "source": [
    "MAX_ITERATIONS = 50\n",
    "d = 0.85\n",
    "threshold = 0.0001  # convergence threshold\n",
    "\n",
    "\n",
    "for iter in range(MAX_ITERATIONS):\n",
    "    # threshold 때문에 만듬\n",
    "    prev_score = np.copy(score)\n",
    "\n",
    "    for i in range(vocab_len):\n",
    "        summation = 0\n",
    "        for j in range(vocab_len):\n",
    "            summation += weighted_edge[j][i] * score[j]\n",
    "\n",
    "        score[i] = (1-d) + d*summation\n",
    "        print(\"***** score *****\")\n",
    "        print(score)\n",
    "    # np.fabs flaot 절대값(abs)\n",
    "    if np.sum(np.fabs(prev_score - score)) <= threshold:\n",
    "        break\n",
    "        \n",
    "print(\"***** final *****\")\n",
    "print(score)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wia32INGlyhA"
   },
   "source": [
    "### 5) 핵심 단어 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T15:32:06.926313Z",
     "start_time": "2021-07-10T15:32:06.920707Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DMVQR-TqlyhB",
    "outputId": "8d26cce6-2850-46ef-d8d8-4bc71aa51ba4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 핵심키워드 ===\n",
      "딸기 : 1.4669365\n",
      "바나나 : 0.98370874\n",
      "사과 : 0.9837059\n",
      "파인애플 : 0.56562966\n"
     ]
    }
   ],
   "source": [
    "# np.argsort() <-- sort array and return index\n",
    "sorted_index = np.flip(np.argsort(score), 0)\n",
    "\n",
    "n = 4\n",
    "\n",
    "print(\"\\n=== 핵심키워드 ===\")\n",
    "for i in range(0, n):\n",
    "    print(str(idx2vocab[sorted_index[i]])+\" : \" + str(score[sorted_index[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T15:32:18.714557Z",
     "start_time": "2021-07-10T15:32:18.712341Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AXThGqhpOoaU",
    "outputId": "7533a999-e6b9-4a27-cc82-9f6dca2c393a"
   },
   "outputs": [],
   "source": [
    "# sorted_index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T15:32:26.857081Z",
     "start_time": "2021-07-10T15:32:26.627717Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "ZYWGsT6UROhs",
    "outputId": "8739807a-91b4-48c9-b77e-0a4f8a0009a7"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "\n",
    "def get_news_by_url(url):\n",
    "    headers = {\"user-agent\": \"Mozilla/5.0\"}\n",
    "    res = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "    content = soup.select_one(\n",
    "        \"#articleBodyContents\").get_text().replace(\"\\n\", \"\")\n",
    "    content = content.replace(\n",
    "        \"// flash 오류를 우회하기 위한 함수 추가function _flash_removeCallback() {}\", \"\")\n",
    "\n",
    "    start_pos = re.search(r\"\\w+@\\w+\\.\\w+(.\\w+)?\", content).start()\n",
    "    content = content[:start_pos-1]\n",
    "    return content\n",
    "\n",
    "\n",
    "doc = get_news_by_url(\n",
    "    'https://news.naver.com/main/read.nhn?mode=LSD&mid=sec&sid1=105&oid=018&aid=0004430108')\n",
    "doc = re.sub(\"[^가-힣 \\d]\", \" \", doc)\n",
    "#doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QmtIyyHlygg"
   },
   "source": [
    "### 1) 토큰화 (Tokenization)\n",
    "\n",
    "분석 텍스트 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T15:32:37.769638Z",
     "start_time": "2021-07-10T15:32:37.720140Z"
    },
    "id": "scz7N1PVFRBl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['과기', '정통부', '22', '일', '유영민', '장관', '등', '참석', '해', '기념행사']\n",
      "['과기', '정통부', '유영민', '장관', '참석', '기념행사', '투입', '여종', '데이터', '구축']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()\n",
    "\n",
    "tokens = [ token for token in mecab.pos(doc) ]\n",
    "nodes = [t[0] for t in tokens]\n",
    "vocab = [t[0] for t in tokens if t[1] in ['NNG', 'NNP'] and len(t[0]) > 1]\n",
    "\n",
    "print(nodes[:10])\n",
    "print(vocab[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBJSuIvKlygw"
   },
   "source": [
    "### 2) Unique한 토큰 목록 생성\n",
    "\n",
    "그래프 생성을 위해서 Unique한 토큰 목록 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T15:33:03.994259Z",
     "start_time": "2021-07-10T15:33:03.991044Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab = list(set(vocab))\n",
    "\n",
    "vocab2idx = {vocab[i]: i for i in range(len(vocab))}\n",
    "idx2vocab = {i: vocab[i] for i in range(len(vocab))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T15:33:05.352131Z",
     "start_time": "2021-07-10T15:33:04.564788Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h5_DwRpOlygz",
    "outputId": "e726eaa0-13e8-4722-d9c8-afef06176550"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 핵심키워드 ===\n",
      "데이터 : 7.405189e-07\n",
      "센터 : 2.49831e-07\n",
      "한국 : 2.0378042e-07\n",
      "활용 : 1.9834519e-07\n",
      "대한 : 1.9389464e-07\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "vocab_len = len(vocab2idx)\n",
    "\n",
    "# 토큰별로 그래프 edge를 Matrix 형태로 생성\n",
    "weighted_edge = np.zeros((vocab_len, vocab_len), dtype=np.float32)\n",
    "\n",
    "# 각 토큰 노드별로 스코어 1로 초기화\n",
    "score = np.ones((vocab_len), dtype=np.float32)\n",
    "\n",
    "# coocurrence를 판단하기 위한 window 사이즈 설정\n",
    "window_size = 3\n",
    "covered_coocurrences = []\n",
    "\n",
    "for window_start in range(len(nodes) - window_size + 1):\n",
    "    window = nodes[window_start:window_start+window_size]\n",
    "    for i in range(window_size):\n",
    "        for j in range(i+1, window_size):\n",
    "            if window[i] in vocab and window[j] in vocab:\n",
    "                index_i = window_start + i\n",
    "                index_j = window_start + j\n",
    "\n",
    "                if (index_i, index_j) not in covered_coocurrences:\n",
    "                    weighted_edge[vocab2idx[window[i]]\n",
    "                                  ][vocab2idx[window[j]]] = 1\n",
    "                    weighted_edge[vocab2idx[window[j]]\n",
    "                                  ][vocab2idx[window[i]]] = 1\n",
    "                    covered_coocurrences.append((index_i, index_j))\n",
    "\n",
    "for i in range(vocab_len):\n",
    "    row_sum = weighted_edge[i].sum()\n",
    "    weighted_edge[i] = weighted_edge[i]/row_sum if row_sum > 0 else 0\n",
    "\n",
    "MAX_ITERATIONS = 50\n",
    "d = 0.85\n",
    "threshold = 0.0001  # convergence threshold\n",
    "\n",
    "for iter in range(MAX_ITERATIONS):\n",
    "    prev_score = np.copy(score)\n",
    "\n",
    "    for i in range(vocab_len):\n",
    "        summation = 0\n",
    "        for j in range(vocab_len):\n",
    "            if weighted_edge[j][i] != 0:\n",
    "                summation += weighted_edge[j][i] * prev_score[j]\n",
    "\n",
    "        score[i] = (1 - d) * d*summation\n",
    "\n",
    "    if np.sum(np.fabs(prev_score - score)) <= threshold:\n",
    "        break\n",
    "\n",
    "\n",
    "sorted_index = np.flip(np.argsort(score), 0)\n",
    "\n",
    "n = 5\n",
    "\n",
    "\n",
    "print(\"\\n=== 핵심키워드 ===\")\n",
    "for i in range(0, n):\n",
    "    print(str(idx2vocab[sorted_index[i]])+\" : \" + str(score[sorted_index[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vOuNI7WSBcgU"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZ8Uu6Rqbfyi"
   },
   "source": [
    "## 그래프 활용 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "683iA8igbfym"
   },
   "source": [
    "### 1) 토큰화 (Tokenization)\n",
    "\n",
    "분석 텍스트 정제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iY8re-9gbfy9"
   },
   "source": [
    "### 2) 그래프 생성 (weighted edge 계산)\n",
    "\n",
    "*   TextRank는 그래프 기반 모델\n",
    "*   각 단어(토큰)은 그래프의 노드(vertex) 없음을 의미\n",
    "*   모든 노드는 1로 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T15:33:47.079894Z",
     "start_time": "2021-07-10T15:33:46.785126Z"
    },
    "id": "phYnQIcBbfy9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import networkx as nx\n",
    "\n",
    "# 윈도내 동시 등장한 토큰으로 그래프를 생성\n",
    "\n",
    "\n",
    "def connect(vocab, nodes):\n",
    "    window_size = 3\n",
    "    \n",
    "    edges = []\n",
    "    for window_start in range(len(nodes)-window_size +1):\n",
    "        window = nodes[window_start: window_start + window_size]\n",
    "        for i in range(window_size):\n",
    "            for j in range(i + 1,window_size):\n",
    "                if window[i] in vocab and window[j] in vocab:\n",
    "                    edges.append((window[i], window[j]))\n",
    "    return edges\n",
    "\n",
    "graph = nx.diamond_graph()\n",
    "graph.clear()\n",
    "graph.add_nodes_from(list(set(nodes)))  # node 등록\n",
    "graph.add_edges_from(connect(nodes, tokens))  # edge 연결"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3c4KZdyufiBM"
   },
   "source": [
    "### 3) 스코어 계산 및 핵심키워드 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T15:33:52.514936Z",
     "start_time": "2021-07-10T15:33:52.501160Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h5pHA1WverhB",
    "outputId": "7e6efd67-2365-4a03-8222-38d6a33f600b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 핵심키워드 ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('물론', 0.0027472527472527405),\n",
       " ('문', 0.0027472527472527405),\n",
       " ('출범식', 0.0027472527472527405),\n",
       " ('최신', 0.0027472527472527405),\n",
       " ('생태', 0.0027472527472527405)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = nx.pagerank(graph)  # pagerank 계산\n",
    "rank = sorted(scores.items(), key=lambda x: x[1], reverse=True)  # score 역순 정렬\n",
    "print(\"\\n=== 핵심키워드 ===\")\n",
    "rank[:5]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "hpTxmnbx8v6m"
   ],
   "name": "08 Prac 2. Keyword Extraction",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
